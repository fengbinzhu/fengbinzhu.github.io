
<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta content="IE=7.0000" http-equiv="X-UA-Compatible">
<title>Fengbin Zhu's Homepage</title>

<meta name="description" content="Fengbin Zhu, Êú±Âá§ÂΩ¨ÔºåfengbinÔºå Research Fellow, Document Intelligence, Document Understanding, FinTech, large language models, multi-modal language model, natural language processing">
<meta name="keywords" content="Fengbin Zhu, Fengbin, Êú±Âá§ÂΩ¨Ôºå NUS, National University of Singapore, document understanding, document intelligence, fine-grained visual understanding, fintech, finance, TAT-QA, MMDocBench">

<link rel="icon" href="./images/fengbin.ico">
<link rel="stylesheet" type="text/css" href="./files/fengbin.css">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Z4T9JQ0JDR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Z4T9JQ0JDR');
</script>

<style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>


<body>

<div id="content">

<div id="news">
    <h2>News</h2><br>
    <font size="3px">
		
	<b>Jan 2026</b><br> 
    <span class="easylink">
    „ÄêSurvey„ÄëWe have released a comprehensive <a href="https://www.preprints.org/frontend/manuscript/11cab45ab0d578f7080de19423eb6ffe/download_pub" target="_blank"> survey paper</a> to investigate the <b>  Mechanisms of Multi-Step Reasoning (e.g., chain of thought) in LLMs</b> through two distinct paradigms: Implicit Reasoning and Explicit Reasoning.
	</span><br><br>	
		
	<b>Dec 2025</b><br>
    <span class="easylink">
    „ÄêTMLR„ÄëOne paper has been accepted by Transactions on Machine Learning Research (TMLR) about <b>Embedding Scaling in Recommendation System</b>!
    </span><br><br>	
		
	<b>Oct 2025</b><br>
    <span class="easylink">
    „ÄêMMM'26„ÄëThe paper of <a href="https://mmdocbench.github.io/" target="_blank">MMDocBench</a> has been accepted by MMM 2026!
    </span><br><br>	
		
	 <b>Sep 2025</b><br>
    <span class="easylink">
    „ÄêNeurIPs'25„ÄëOne paper has been accepted by NeurIPs 2025 about <b>LLM-based Personalized Recommendation</b>!
    </span><br><br>
		
	 <b>Aug 2025</b><br>
    <span class="easylink">
    „ÄêICAIF'25„ÄëWe are organizing a <b>Financial Document Deep Research (FinDDR)</b> Grand Challenge at ICAIF'25; The <a href="https://finddr2025.github.io/" target="_blank">Official Website</a> is available now!
    </span><br><br>
		
	 <b>Aug 2025</b><br>
    <span class="easylink">
    „ÄêAAAI'26„Äë We are organizing the <b>Agentic AI in Financial Services</b> Workshop at AAAI'26; The <a href="https://ai-4-finance.pages.dev/"  target="_blank">Official Website and CFP </a> are available now!
    </span><br><br>
		
    <b>Aug 2025</b><br>
    <span class="easylink">
     „ÄêEMNLP'25„Äë One full paper has been accepted by EMNLP'25 about <b>LLM Personalization</b>.
    </span><br><br>
		
    <b>Jul 2025</b><br>
    <span class="easylink">
     „ÄêMM'25„Äë Two full papers have been accepted by ACM MM'25: one paper about <b>Temporal-Aware Multi-Modal
RAG</b> in finance and the other about <b>LLM-based Personalized Image Generation</b>. 
    </span><br><br>
	    
   <b>Jul 2025</b><br>
    <span class="easylink">
     „ÄêRecSys'25„Äë One full paper has been accepted by RecSys'25 about <b>Heterogeneous User Modeling for Open-domain Recommendation </b>
    </span><br><br>
	    
    <b>Apr 2025</b><br>
    <span class="easylink">
     „ÄêSIGIR'25„Äë We are giving a Tutorial titled <b>Long Context vs. RAG: Strategies for Processing Long Documents in LLMs</b>. The <a href="https://sites.google.com/view/sigir25-lc-vs-rag/" target="_blank">Official Website</a> is available now.
    </span><br><br>
	    
    <b>Apr 2025</b><br>
    <span class="easylink">
    „ÄêSIGIR'25„Äë One full paper has been accepted by SIGIR'25 about <b>Zero-shot Sketch-based Image Retrieval</b>.
    </span><br><br>
	    
     <b>Mar 2025</b><br>
    <span class="easylink">
    „ÄêICAIF'25„Äë We will host the <b>ACM International Conference on AI in Finance (ICAIF) 2025</b> in Singapore! The <a href="https://icaif25.org/" target="_blank">Official Website</a> is available now! 
    </span><br><br>

     <b>Feb 2025</b><br>
    <span class="easylink">
    „ÄêSIGIR'25„Äë We are organizing the <b>FinIR workshop</b> at SIGIR'25; The <a href="https://finir2025.github.io/" target="_blank">Official Website</a> is available now.
    </span><br><br>
	    
    <b>Jan 2025</b><br>
    <span class="easylink">
      Two papers are accepted by WWW'25, one Oral paper about <b>LLM-powered Agents</b> and one Short paper about <b>Memory Retrieval</b> for Generative Recommendation.
    </span><br><br>
	    
    <b>Dec 2024</b><br>
    <span class="easylink">
      One paper is accepted by AAAI'25 (Oral) about <b>Combating Misinformation</b> in RAG </b>.
    </span><br><br>
	    
    <b>Oct 2024</b><br>
    <span class="easylink">
      <a href="https://mmdocbench.github.io/" target="_blank"><b>MMDocBench</b></a> is released, which is designed to evaluate <b>large vision-language models(LVLMs)</b> in <b>fine-grained visual document understanding</b>.
    </span><br><br>

    <b>Sep 2024</b><br>
    <span class="easylink">
      One paper is accepted by ICAIF'24 (Oral) about <b>LLM training and specialization</b> for <b>understanding and reasoning over financial table-text data</b>.
    </span><br><br>

    <b>Sep 2024</b><br>
    <span class="easylink">
      One paper is accepted by EMNLP'24 Findings about <b>prompt tuning</b>, <b>robust prompt optimization</b>, and <b>trustiness</b> of <b>large language models (LLMs)</b>.
    </span><br><br>


     <b>Feb 2024</b><br>
    <span class="easylink">
      One paper is accepted by LREC-COLING'24 about <b>Graph-based representation</b> for <b>understanding and reasoning over financial table-text data</b>.
    </span><br><br>

    </font>

</div>

<div id="left">
<table style="background-color:white;">
<tbody><tr nosave="">
<td valign="CENTER">
<img src="./images/fengbin.jpeg" height="200" align="left">
</td>

<!-- <td valign="CENTER" width="1%"> -->
<!-- </td> -->

<td valign="CENTER" halign="LEFT">
<font size="+0">
<b><font size="+2">Fengbin Zhu&nbsp;</font></b>
<!--<p style="margin-left:0px;">
<img src="./images/name.png", height="60">
</p>-->
<p style="margin-left:0px;">

<b>Postdoctoral Research Fellow</b>
</p><p style="margin-left:0px;">
<a href="http://www.nextcenter.org/", target="_blank">NExT++</a><br/>
<a href="https://www.comp.nus.edu.sg/", target="_blank">School of Computing</a><br/>
<a href="http://www.nus.edu.sg", target="_blank">National University of Singapore</a><br/>
</p><p style="margin-left:0px;">
COM4, 3A Research Link, Singapore 119392<br>
</p><p style="margin-left:0px;">
Email: zhfengbin AT gmail.com or fengbin AT nus.edu.sg </a><br>
&bull; <a href="https://scholar.google.com/citations?user=-rxzvfcAAAAJ&hl=en">Google Scholar</a> &bull; <a href="https://www.linkedin.com/in/fengbin-zhu/">LinkedIn</a> &bull; <a href="https://github.com/fengbinzhu">GitHub</a>  <br>
</p></font><p><font size="+0">
</font>
</p></td>
</tr>
</tbody></table>

<div style="margin-top:20px;">
  I am a Postdoc Research Fellow at <a href="https://www.nextcenter.org/" , target="_blank"> NExT Research Center </a> National University of Singapore (NUS), working with  <a href="https://www.chuatatseng.com/" , target="_blank"> Prof. Tat-Seng Chua</a>. My research interests include Multimodal/Heterogeneous Retrieval, Understanding and Reasoning, LLM Evaluation, Agents and AI for Finance. 
</div>

	
<!-- =======================================================================!-->

<div style="CLEAR: both;">
    <font color='red'>
        <h3>Collaboration Opportunities:</h3>
        I am currently seeking highly motivated PhD, Master, and Undergraduate students who are interested in research collaboration on topics such as multimodal understanding and reasoning, LLM-based agents, information retrieval, and AI for finance. <br> <br>

        If you are passionate about these areas and would like to join our team or collaborate, please feel free to reach out with your CV at <a href="mailto:fengbin@nus.edu.sg">fengbin@nus.edu.sg</a>.
    </font>
</div>

<br>

<!-- ==== ADVERTISEMENT SECTION FOR IMPORTANT WORKS ==== -->
<div id="important-work-advert" style="border: 1px solid #DAA520; border-radius: 12px; background: #FFFDE7; padding: 6px;">
  <h3 style="margin-top: 0; color: #B8860B;">
    üöÄ Highlights
  </h3>
  <ul style="list-style-type: disc; margin-left: 25px; font-size: 16px; padding-left: 0;">
    <li style="margin-bottom: 13px;">
      <strong>OpenFinArena Platform:</strong>
      We have released the <a href="https://OpenFinArena.com" target="_blank">OpenFinArena Platform</a> ‚Äî A Premier Platform for Evaluating Professional Financial AI Assistants!
    </li>
    <li style="margin-bottom: 13px;">

      <strong>New Survey Paper:</strong>
      <a href="https://www.preprints.org/frontend/manuscript/11cab45ab0d578f7080de19423eb6ffe/download_pub" target="_blank">Opening the Black Box: A Survey on the Mechanisms of Multi-Step Reasoning in LLMs</a>
      ‚Äî A comprehensive survey of implicit and explicit reasoning paradigms in large language models.
    </li>


  </ul>
</div>

	
<!-- =======================================================================!-->
<h2 style="CLEAR: both;">Surveys, Conferences, Workshops, Tutorials and Competitions</h2>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://www.preprints.org/frontend/manuscript/11cab45ab0d578f7080de19423eb6ffe/download_pub" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">[Survey] Opening the Black Box: A Survey on the Mechanisms of Multi-Step Reasoning in Large Language Models</span> 
     <br>Liangming Pan, Jason Liang, Jiaran Ye, Minglai Yang, Xinyuan Lu, <strong>Fengbin Zhu</strong>
	<br>Preprints 2026
  </td>
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://finddr2025.github.io/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">[Competition] Financial Document Deep Research (FinDDR) Competition @ ACM ICAIF 2025</span> 
    <br> ACM ICAIF 2025 &nbsp;&nbsp; <a href="https://finddr2025.github.io/" target="_blank">Website</a>
  </td>
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://icaif25.org/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">[Conference] The 6th ACM International Conference on AI in Finance (ICAIF) 2025</span> 
    <br> Singapore &nbsp;&nbsp;  <a href="https://icaif25.org/" target="_blank">Website</a>
  </td>
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">[Workshop] The 2nd Workshop on Financial Information Retrieval (FinIR) in the Era of Generative AI</span> 
      <br><b>Fengbin Zhu</b>, Yunshan Ma, Fuli Feng, Chao Wang, Huanbo Luan, Guangnan Ye, Shuo Zhang, Dhagash Mehta, Pingping Chen, Bing Xiang, Tat-Seng Chua
    <br>SIGIR 2025 &nbsp;&nbsp; <a href="https://finir2025.github.io/" target="_blank">Website</a>
  </td>
  </tr>
 </tbody>
</table>

	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">[Tutorial] Long Context vs. RAG: Strategies for Processing Long Documents in LLMs</span> 
      <br>Xinze Li, Yushi Bai, Bowen Jin, <b>Fengbin Zhu</b>, Liangming Pan and Yixin Cao
    <br>SIGIR 2025 (Tutorial) &nbsp;&nbsp; <a href="https://sites.google.com/view/sigir25-lc-vs-rag/" target="_blank">Website</a> 
  </td>
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2408.04223" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">[Survey] VideoQA in the Era of LLMs: An Empirical Study</span> 
      <br>Junbin Xiao, Nanxin Huang, Hangyu Qin, Dongyang Li, Yicong Li, <strong>Fengbin Zhu</strong>, Zhulin Tao, Jianxing Yu, Liang Lin, Tat-Seng Chua, Angela Yao
    <br>IJCV 2025
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2101.00774" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">[Survey] Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering</span> 
      <br><strong>Fengbin Zhu</strong>, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, Tat-Seng Chua
    <br>Arxiv 2021
  </td> 
  </tr>
 </tbody>
</table>
	

<!-- =======================================================================!-->


<div id="papers">
<h2 style="CLEAR: both">Publications <a href="https://scholar.google.com/citations?user=-rxzvfcAAAAJ&hl=en" target="_blank">Google Scholar</a> </h2> &nbsp;&nbsp;  #Equal Contribution  &nbsp;&nbsp;  *Corresponding Author 
</br>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2510.13936" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">FinDeepResearch: Evaluating Deep Research Agents in Rigorous Financial Analysis</span> 
     <br><strong>*Fengbin Zhu</strong>, Xiang Yao Ng, Ziyang Liu, Chang Liu, Xianwei Zeng, Chao Wang, Tianhui Tan, Xuan Yao, Pengyang Shao, Min Xu, Zixuan Wang, Jing Wang, Xin Lin, Junfeng Li, Jingxian Zhu, Yang Zhang, Wenjie Wang, Fuli Feng, Richang Hong, Huanbo Luan, Ke-Wei Huang, Tat-Seng Chua
	   <br>Arxiv 2025
  </td>
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2509.15709" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Understanding Embedding Scaling in Collaborative Filtering</span> 
      <br> Yicheng He, Zhou Kaiyu, Haoyue Bai,  <strong>Fengbin Zhu</strong>, Yonghui Yang
    <br>TMLR (2025)
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2506.13229" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation</span> 
      <br>Zijie Lin, *Yang Zhang, Xiaoyan Zhao, <strong>*Fengbin Zhu</strong>, Fuli Feng, Tat-Seng Chua
    <br>NeurIPs 2025 
  </td> 
  </tr>
 </tbody>
</table>

	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2507.20849" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Latent Inter-User Difference Modeling for LLM Personalization</span> 
      <br>Yilun Qiu, Tianhao Shi, Xiaoyan Zhao, <strong>Fengbin Zhu</strong>, Yang Zhang, Fuli Feng
    <br>EMNLP 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2504.17349" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition</span> 
      <br>Yiyan Xu, Wuqiang Zheng, Wenjie Wang, <strong>Fengbin Zhu</strong>, Xinting Hu, Yang Zhang, Fuli Feng, and Tat-Seng Chua
    <br>MM 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/pdf/2503.05185" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Towards Temporal-Aware Multi-Modal Retrieval Augmented Generation in Finance</span> 
      <br><strong>#Fengbin Zhu</strong>, #Junfeng Li, Liangming Pan, Wenjie Wang, Fuli Feng, Chao Wang, Huanbo Luan, and Tat-Seng Chua
    <br>MM 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Heterogeneous User Modeling for LLM-based Recommendation</span> 
      <br>Honghui Bao, Wenjie Wang, *Xinyu Lin,<strong>*Fengbin Zhu</strong>, Teng Sun, Fuli Feng and Tat-Seng Chua
    <br>RecSys 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/10.1145/3726302.3730108" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Unified Category and Style Generalization for Instance-Level Sketch Retrieval</span> 
      <br>Zechao Hu, Zhengwei Yang, Hao Li, Yixiong Zou, <strong>Fengbin Zhu</strong>, and Zheng Wang
    <br>SIGIR 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2410.17236" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Large Language Models Empowered Personalized Web Agents</span> 
      <br>Hongru Cai, Yongqi Li, Wenjie Wang, <strong>Fengbin Zhu</strong>, Xiaoyu Shen, Wenjie Li, and Tat-Seng Chua
    <br>WWW 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2412.17593" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Leveraging Memory Retrieval to Enhance LLM-based Generative Recommendation</span> 
     <br>Chengbing Wang, *Yang Zhang, *<strong>Fengbin Zhu</strong>, Jizhi Zhang, Tianhao Shi, Fuli Feng
     <br>WWW 2025 (Short)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2406.11497" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG</span> 
      <br>Boyi Deng, *Wenjie Wang, *<strong>Fengbin Zhu</strong>, Qifan Wang, and Fuli Feng
    <br>AAAI 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>

	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2502.06148" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection</span> 
      <br>Yan Weng, *<strong>Fengbin Zhu</strong>, Tong Ye, Haoyan Liu, *Fuli Feng, Tat-Seng Chua
    <br>Arxiv 2025
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2502.02061" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Reason4Rec: Large Language Models for Recommendation with Deliberative User Preference Alignment</span> 
      <br>Yi Fang, Wenjie Wang, Yang Zhang, <strong>Fengbin Zhu</strong>, Qifan Wang, Fuli Feng, Xiangnan He
    <br>Arxiv 2025
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2410.21311" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding and Grounding</span> 
      <br><strong>Fengbin Zhu</strong>, Ziyang Liu, Xiang Yao NG, Haohui Wu, Wenjie Wang, Fuli Feng, Chao Wang, Huanbo Luan, and Tat-Seng Chua
    <br>MMM 2026
  </td> 
  </tr>
 </tbody>
</table>
	

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2401.13223" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">TAT-LLM: A Specialized Language Model for Discrete Reasoning over Financial Tabular and Textual Data</span> 
      <br><strong>Fengbin Zhu</strong>, Ziyang Liu, Fuli Feng,  Chao Wang, Moxin Li and Tat-Seng Chua
    <br>ICAIF 2024 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2403.09972" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection</span> 
      <br>Moxin Li, Wenjie Wang, Fuli Feng, <strong>Fengbin Zhu</strong>, Qifan Wang, Tat-Seng Chua
    <br>EMNLP 2024 (Findings)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://aclanthology.org/2024.lrec-main.456/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents via Semantic-Oriented Hierarchical Graphs</span> 
      <br><strong>Fengbin Zhu</strong>, Chao Wang, Fuli Feng, Zifeng Ren, Moxin Li, Tat-Seng Chua
    <br>LREC-COLING 2024 (Poster)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/abs/10.1145/3543873.3587598" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">SoarGraph: Numerical Reasoning over Financial Table-Text Data via Semantic-Oriented Hierarchical Graphs</span> 
      <br><strong>Fengbin Zhu</strong>, Moxin Li, Junbin Xiao, Fuli Feng, Chao Wang, Tat Seng Chua
    <br>WWW 2023 (Workshop)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548422/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Towards Complex Document Understanding By Discrete Reasoning</span> 
      <br><strong>Fengbin Zhu</strong>, Wenqiang Lei, Fuli Feng, Chao Wang, Haozhou Zhang, Tat-Seng Chua
    <br>ACM MM 2022 (Poster)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://aclanthology.org/2022.acl-long.5/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Learning to Imagine: Integrating Counterfactual Thinking in Neural Discrete Reasoning</span> 
      <br>Moxin Li, Fuli Feng, Hanwang Zhang, Xiangnan He, <strong>Fengbin Zhu</strong>, Tat-Seng Chua
    <br>ACL 2022 (Poster)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://aclanthology.org/2021.acl-long.254/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance</span> 
      <br><strong>Fengbin Zhu</strong>, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, Tat-Seng Chua
    <br>ACL 2021 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>


<h2 style="CLEAR: both;">Professional Services</h2>
<table><tbody><tr><td>
	Member of the <span class="title">Executive Committee of ACM International Conference on AI in Finance (ICAIF) </span> <br>
	Member of the <span class="title">Executive Committee of CCF Digital Finance </span> <br>
    Local Co-chair of <span class="title">ACM ICAIF (2025) </span> <br>
	Area Chair of <span class="title">ACL (2025, 2026) </span> <br>
	Area Chair of <span class="title">ACM ICMR (2026) </span> <br>
    PC Member of <span class="title">ACM WWW (2026) </span> <br>
    PC Member of <span class="title">ACM WSDM (2026) </span> <br>
	PC Member of <span class="title">ACM SIGIR (2025) </span> <br> 
    PC Member of <span class="title">ICCV (2025) </span> <br>
    PC Member of <span class="title">ACL ARR (2024, 2025, 2026) </span> <br>
    PC Member of <span class="title">COLING (2025) </span> <br>
    PC Member of <span class="title">ACM MM (2022, 2023, 2024, 2025) </span> <br>
    PC Member of <span class="title">AAAI (2023, 2024, 2025, 2026)  </span> <br>
    Invited Reviewer for <span class="title">IEEE TKDE, TMM, TIP, TBD, TCSVT</span> <br>
    Invited Reviewer for <span class="title">ACM CSUR, TOIS, TOMM </span> <br>
</td></tr></tbody></table>

<h2 style="CLEAR: both;">Education</h2>
<table>
  <tbody>
  <tr>
    <td><span class="title">National University of Singapore (NUS)</span> <br>
	Ph.D. in Computer Science &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Aug 2019 - Jun 2024, Singapore <br>
	Advisor: <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a><br>
	Mentors: <a href="https://fulifeng.github.io/" target="_blank">Prof. Fuli Feng</a>, <a href="https://sites.google.com/view/wenqianghome/home" target="_blank">Prof. Wenqiang Lei</a> and <a href="https://scholar.google.com/citations?user=Mz2W41YAAAAJ&hl=en" target="_blank">Dr. Chao Wang</a>
     </td></tr></tbody></table>
<!-- <table>
  <tbody>
  <tr>
    <td><span class="title">Beihang University (BUAA)</span> <br>
	Bachelor in Computer Science and Engineering &nbsp;&nbsp;&nbsp;&nbsp;  September 2011 - June 2015, Beijing <br>
	Advisor: <a href="https://dblp.org/pers/hd/l/Li:Zhoujun" target="_blank">Prof. Zhoujun Li</a>
    </td></tr></tbody></table> -->

<h2 style="CLEAR: both">Experiences</h2>

<table>
  <tbody><tr>
    <td> <span class="title">Postdoc Research Fellow</span>, National University of Singapore, Jul 2024 -    <br>
			Advisior: <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a> (<a href="http://www.nextcenter.org/" target="_blank">NExT++: NUS-Tsinghua-Southampton Extreme Search Center</a>)
		</td></tr></tbody>
</table>

<table>
  <tbody><tr>
    <td> <span class="title">Technology Director</span>, <a href="https://www.6estates.com/about" target="_blank"> 6Estates Pte Ltd</a>, Mar 2015 -  
    </td></tr></tbody>
</table>

<table>
  <tbody><tr>
    <td> <span class="title">Research Assistant</span>, National University of Singapore, Mar 2012 - Mar 2015  <br>
      Advisior: <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a> (<a href="http://www.nextcenter.org/" target="_blank">NExT: NUS-Tsinghua Extreme Search Center</a>)
    </td></tr></tbody>
</table>

<h2 style="CLEAR: both;">Selected Awards</h2>


<table><tbody><tr><td>
  <span class="title">Research Achievement Award, &nbsp;&nbsp; 2022</span> &nbsp;&nbsp;
  <br> - School of Computing, National University of Singapore
</td></tr></tbody></table>

<table><tbody><tr><td>
  <span class="title"> Winner of 1st Competition on Chinese Machine Reading Comprehension (CMRC), &nbsp;&nbsp;2017</span> &nbsp;&nbsp;
  <br> - 16th China National Conference on Computational Linguistics (CCL)
</td></tr></tbody></table>

</br>

<a href='https://clustrmaps.com/site/1c1sz'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=200&t=m&d=gD2pgA_cxi0YfQEqH8dCL4qwueAnp0B1NOY6Z5eV46g'/></a>

</br>

<div>
Last update: Dec, 2025. Webpage template borrows from <a href="https://fulifeng.github.io/">Prof. Fuli Feng</a> and <a href="https://hexiangnan.github.io/">Prof. Xiangnan He</a>.</div>

</div>
</div>


</body></html>
