
<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta content="IE=7.0000" http-equiv="X-UA-Compatible">
<title>Fengbin Zhu's Homepage</title>

<meta name="description" content="Fengbin Zhu, Research Fellow, Document Intelligence, Document Understanding, FinTech, large language models, multi-modal language model, natural language processing">
<meta name="keywords" content="Fengbin Zhu, Fengbin, NUS, National University of Singapore, document understanding, document intelligence, fine-grained visual understanding, fintech, finance, TAT-QA, MMDocBench">

<link rel="icon" href="./images/fengbin.ico">
<link rel="stylesheet" type="text/css" href="./files/fengbin.css">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Z4T9JQ0JDR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Z4T9JQ0JDR');
</script>

<style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>


<body>

<div id="content">

<div id="news">
    <h2>News</h2><br>
    <font size="3px">

    <b>Apr 2025</b><br>
    <span class="easylink">
     【SIGIR'25】 We are giving a Tutorial titled <b>Long Context vs. RAG: Strategies for Processing Long Documents in LLMs</b>.
    </span><br><br>
	    
    <b>Apr 2025</b><br>
    <span class="easylink">
    【SIGIR'25】 One full paper has been accepted by SIGIR'25 about <b>Zero-shot Sketch-based Image Retrieval</b>.
    </span><br><br>
	    
     <b>Mar 2025</b><br>
    <span class="easylink">
    【ICAIF'25】 We will host the <b>ACM International Conference on AI in Finance (ICAIF) 2025</b> in Singapore! The official website and CFP will be released soon. Stay tuned! 
    </span><br><br>

     <b>Feb 2025</b><br>
    <span class="easylink">
    【SIGIR'25】 We are organizing the <b>FinIR workshop</b> at SIGIR'25; The <a href="https://finir2025.github.io/" target="_blank">Official Website</a> is available now.
    </span><br><br>
	    
    <b>Jan 2025</b><br>
    <span class="easylink">
      Two papers are accepted by WWW'25, one Oral paper about <b>LLM-powered Agents</b> and one Short paper about <b>Memory Retrieval</b> for Generative Recommendation.
    </span><br><br>
	    
    <b>Dec 2024</b><br>
    <span class="easylink">
      One paper is accepted by AAAI'25 (Oral) about <b>Combating Misinformation</b> in RAG </b>.
    </span><br><br>
	    
    <b>Oct 2024</b><br>
    <span class="easylink">
      <a href="https://mmdocbench.github.io/" target="_blank"><b>MMDocBench</b></a> is released, which is designed to evaluate <b>large vision-language models(LVLMs)</b> in <b>fine-grained visual document understanding</b>.
    </span><br><br>

    <b>Sep 2024</b><br>
    <span class="easylink">
      One paper is accepted by ICAIF'24 (Oral) about <b>LLM training and specialization</b> for <b>understanding and reasoning over financial table-text data</b>.
    </span><br><br>

    <b>Sep 2024</b><br>
    <span class="easylink">
      One paper is accepted by EMNLP'24 Findings about <b>prompt tuning</b>, <b>robust prompt optimization</b>, and <b>trustiness</b> of <b>large language models (LLMs)</b>.
    </span><br><br>


     <b>Feb 2024</b><br>
    <span class="easylink">
      One paper is accepted by LREC-COLING'24 about <b>Graph-based representation</b> for <b>understanding and reasoning over financial table-text data</b>.
    </span><br><br>

    </font>

</div>

<div id="left">
<table style="background-color:white;">
<tbody><tr nosave="">
<td valign="CENTER">
<img src="./images/fengbin.jpeg" height="200" align="left">
</td>

<!-- <td valign="CENTER" width="1%"> -->
<!-- </td> -->

<td valign="CENTER" halign="LEFT">
<font size="+0">
<b><font size="+2">Fengbin Zhu&nbsp;</font></b>
<!--<p style="margin-left:0px;">
<img src="./images/name.png", height="60">
</p>-->
<p style="margin-left:0px;">

<b>Postdoctoral Research Fellow</b>
</p><p style="margin-left:0px;">
<a href="http://www.nextcenter.org/", target="_blank">NExT++</a><br/>
<a href="https://www.comp.nus.edu.sg/", target="_blank">School of Computing</a><br/>
<a href="http://www.nus.edu.sg", target="_blank">National University of Singapore</a><br/>
</p><p style="margin-left:0px;">
COM4, 3A Research Link, Singapore 119392<br>
</p><p style="margin-left:0px;">
Email: zhfengbin AT gmail.com</a><br>
&bull; <a href="https://scholar.google.com/citations?user=-rxzvfcAAAAJ&hl=en">Google Scholar</a> &bull; <a href="https://www.linkedin.com/in/fengbin-zhu/">LinkedIn</a> &bull; <a href="https://github.com/fengbinzhu">GitHub</a>  <br>
</p></font><p><font size="+0">
</font>
</p></td>
</tr>
</tbody></table>

<div style="margin-top:20px;">
  I am a Postdoc Research Fellow at <a href="https://www.nextcenter.org/" , target="_blank"> NExT Research Center </a> National University of Singapore (NUS), working with  <a href="https://www.chuatatseng.com/" , target="_blank"> Prof. Tat-Seng Chua</a>. I earned my PhD from NUS in June 2024, also supervised by Prof. Chua. My research interests include Natural Language Processing (NLP), Information Retrieval (IR), Document Intelligence (DI), and the application of AI in finance. 
</div>

<br>

<!-- =======================================================================!-->

<div>
    <font color='red'>PS: I am actively looking for highly motivated PhD/master/undergraduate students to collaborate on various interesting research topics, including retrieval-augmented generation, multi-modal LLM for document intelligence, financial LLM, and LLM-based agents, etc. If you have interest, please feel free to send your CV to zhfengbin@gmail.com.</font>
</div>

	
<!-- =======================================================================!-->
<h2 style="CLEAR: both;">Conferences, Workshops, Tutorials and Surveys</h2>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://icaif25.org/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">The 6th ACM International Conference on AI in Finance (ICAIF) 2025</span> 
    <br> Singapore &nbsp;&nbsp;  <a href="https://icaif25.org/" target="_blank">Website</a>
  </td>
  </tr>
 </tbody>
</table>
	
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">The 2nd Workshop on Financial Information Retrieval (FinIR) in the Era of Generative AI</span> 
      <br><b>Fengbin Zhu</b>, Yunshan Ma, Fuli Feng, Chao Wang, Huanbo Luan, Guangnan Ye, Shuo Zhang, Dhagash Mehta, Pingping Chen, Bing Xiang, Tat-Seng Chua
    <br>SIGIR 2025 &nbsp;&nbsp; <a href="https://finir2025.github.io/" target="_blank">Website</a>
  </td>
  </tr>
 </tbody>
</table>

	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Long Context vs. RAG: Strategies for Processing Long Documents in LLMs</span> 
      <br>Xinze Li, Yushi Bai, Bowen Jin, <b>Fengbin Zhu</b>, Liangming Pan and Yixin Cao
    <br>SIGIR 2025 
  </td>
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2408.04223" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">VideoQA in the Era of LLMs: An Empirical Study</span> 
      <br>Junbin Xiao, Nanxin Huang, Hangyu Qin, Dongyang Li, Yicong Li, <strong>Fengbin Zhu</strong>, Zhulin Tao, Jianxing Yu, Liang Lin, Tat-Seng Chua, Angela Yao
    <br>IJCV 2025
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2101.00774" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering</span> 
      <br><strong>Fengbin Zhu</strong>, Wenqiang Lei, Chao Wang, Jianming Zheng, Soujanya Poria, Tat-Seng Chua
    <br>Arxiv 2021
  </td> 
  </tr>
 </tbody>
</table>
	

<!-- =======================================================================!-->


<div id="papers">
<h2 style="CLEAR: both">Publications <a href="https://scholar.google.com/citations?user=-rxzvfcAAAAJ&hl=en" target="_blank">Google Scholar</a> </h2> &nbsp;&nbsp;  #Equal Contribution  &nbsp;&nbsp;  *Corresponding Author 
</br>



<!-- <b> In the Year of 2023: </b> </br></br> -->

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2410.17236" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Large Language Models Empowered Personalized Web Agents</span> 
      <br>Hongru Cai, Yongqi Li, Wenjie Wang, <strong>Fengbin Zhu</strong>, Xiaoyu Shen, Wenjie Li, and Tat-Seng Chua
    <br>WWW 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2412.17593" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Leveraging Memory Retrieval to Enhance LLM-based Generative Recommendation</span> 
     <br>Chengbing Wang, *Yang Zhang, *<strong>Fengbin Zhu</strong>, Jizhi Zhang, Tianhao Shi, Fuli Feng
     <br>WWW 2025 (Short)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2406.11497" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG</span> 
      <br>Boyi Deng, *Wenjie Wang, *<strong>Fengbin Zhu</strong>, Qifan Wang, and Fuli Feng
    <br>AAAI 2025 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>

	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2502.06148" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection</span> 
      <br>Yan Weng, *<strong>Fengbin Zhu</strong>, Tong Ye, Haoyan Liu, *Fuli Feng, Tat-Seng Chua
    <br>Arxiv 2025
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2502.02061" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Reason4Rec: Large Language Models for Recommendation with
Deliberative User Preference Alignment</span> 
      <br>Yi Fang, Wenjie Wang, Yang Zhang, <strong>Fengbin Zhu</strong>, Qifan Wang, Fuli Feng, Xiangnan He
    <br>Arxiv 2025
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2410.21311" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding</span> 
      <br><strong>Fengbin Zhu</strong>, Ziyang Liu, Xiang Yao NG, Haohui Wu, Wenjie Wang, Fuli Feng, Chao Wang, Huanbo Luan, and Tat-Seng Chua
    <br>Arxiv 2024
  </td> 
  </tr>
 </tbody>
</table>
	
<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2410.22888" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector</span> 
      <br>#Youcheng Huang, #<strong>Fengbin Zhu</strong>, Jingkun Tang, Pan Zhou, Wenqiang Lei, Jiancheng Lv and Tat-Seng Chua
    <br>Arxiv 2024
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2401.13223" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">TAT-LLM: A Specialized Language Model for Discrete Reasoning over Financial Tabular and Textual Data</span> 
      <br><strong>Fengbin Zhu</strong>, Ziyang Liu, Fuli Feng,  Chao Wang, Moxin Li and Tat-Seng Chua
    <br>ICAIF 2024 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>


<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2403.09972" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Think Twice Before Trusting: Self-Detection for Large Language Models through Comprehensive Answer Reflection</span> 
      <br>Moxin Li, Wenjie Wang, Fuli Feng, <strong>Fengbin Zhu</strong>, Qifan Wang, Tat-Seng Chua
    <br>EMNLP 2024 (Findings)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://aclanthology.org/2024.lrec-main.456/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents via Semantic-Oriented Hierarchical Graphs</span> 
      <br><strong>Fengbin Zhu</strong>, Chao Wang, Fuli Feng, Zifeng Ren, Moxin Li, Tat-Seng Chua
    <br>LREC-COLING 2024 (Poster)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/abs/10.1145/3543873.3587598" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">SoarGraph: Numerical Reasoning over Financial Table-Text Data via Semantic-Oriented Hierarchical Graphs</span> 
      <br><strong>Fengbin Zhu</strong>, Moxin Li, Junbin Xiao, Fuli Feng, Chao Wang, Tat Seng Chua
    <br>WWW 2023 (Workshop)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548422/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Towards Complex Document Understanding By Discrete Reasoning</span> 
      <br><strong>Fengbin Zhu</strong>, Wenqiang Lei, Fuli Feng, Chao Wang, Haozhou Zhang, Tat-Seng Chua
    <br>ACM MM 2022 (Poster)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://arxiv.org/abs/2206.06890" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">RDU: A Region-based Approach to Form-style Document Understanding</span> 
      <br><strong>Fengbin Zhu</strong>, Chao Wang, Wenqiang Lei, Ziyang Liu, Tat Seng Chua
    <br>Arxiv 2022
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://aclanthology.org/2022.acl-long.5/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">Learning to Imagine: Integrating Counterfactual Thinking in Neural Discrete Reasoning</span> 
      <br>Moxin Li, Fuli Feng, Hanwang Zhang, Xiangnan He, <strong>Fengbin Zhu</strong>, Tat-Seng Chua
    <br>ACL 2022 (Poster)
  </td> 
  </tr>
 </tbody>
</table>

<table>
  <tbody>
  <tr>
    <td class="left"><a href="https://aclanthology.org/2021.acl-long.254/" target="_blank"><img src="./images/pdf.png" width="25" height="25"><br>pdf</a></td>
    <td><span class="title">TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance</span> 
      <br><strong>Fengbin Zhu</strong>, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, Tat-Seng Chua
    <br>ACL 2021 (<font color='red'>Oral</font>)
  </td> 
  </tr>
 </tbody>
</table>



<h2 style="CLEAR: both;">Professional Services</h2>
<table><tbody><tr><td>
    Local co-chair of <span class="title">ACM International Conference on AI in Finance (ICAIF 2025) </span> <br>
    Co-organizer of <span class="title">The 2nd Financial Information Retrieval (FinIR) Workshop at SIGIR 2025 </span> <br>
    Session Chair of <span class="title">ACM International Conference on AI in Finance (ICAIF 2024)  </span> <br>
    Program Committee Member of <span class="title">ACM SIGIR (2025) </span> <br>
    Program Committee Member of <span class="title">ICCV (2025) </span> <br>
    Program Committee Member of <span class="title">ACL ARR (2024, 2025) </span> <br>
    Program Committee Member of <span class="title">COLING (2025) </span> <br>
    Program Committee Member of <span class="title">ACM MM (2022, 2023, 2024) </span> <br>
    Program Committee Member of <span class="title">AAAI (2023, 2024)  </span> <br>
    Invited Reviewer for <span class="title">IEEE TKDE, TMM, TIP, TBD, TCSVT </span> <br>
    Invited Reviewer for <span class="title">ACM TOIS, TOMM </span> <br>
</td></tr></tbody></table>

<h2 style="CLEAR: both;">Education</h2>
<table>
  <tbody>
  <tr>
    <td><span class="title">National University of Singapore (NUS)</span> <br>
	Ph.D. in Computer Science &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Aug 2019 - Jun 2024, Singapore <br>
	Advisor: <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a><br>
	Mentors: <a href="https://fulifeng.github.io/" target="_blank">Prof. Fuli Feng</a>, <a href="https://sites.google.com/view/wenqianghome/home" target="_blank">Prof. Wenqiang Lei</a> and <a href="https://scholar.google.com/citations?user=Mz2W41YAAAAJ&hl=en" target="_blank">Dr. Chao Wang</a>
     </td></tr></tbody></table>
<!-- <table>
  <tbody>
  <tr>
    <td><span class="title">Beihang University (BUAA)</span> <br>
	Bachelor in Computer Science and Engineering &nbsp;&nbsp;&nbsp;&nbsp;  September 2011 - June 2015, Beijing <br>
	Advisor: <a href="https://dblp.org/pers/hd/l/Li:Zhoujun" target="_blank">Prof. Zhoujun Li</a>
    </td></tr></tbody></table> -->

<h2 style="CLEAR: both">Experiences</h2>

<table>
  <tbody><tr>
    <td> <span class="title">Postdoc Research Fellow</span>, National University of Singapore, Jul 2024 - Present   <br>
			Advisior: <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a> (<a href="http://www.nextcenter.org/" target="_blank">NExT++: NUS-Tsinghua-Southampton Extreme Search Center</a>)
		</td></tr></tbody>
</table>

<table>
  <tbody><tr>
    <td> <span class="title">Technology Director</span>, <a href="https://www.6estates.com/about" target="_blank"> 6Estates Pte Ltd</a>, Mar 2015 - Jun 2024 
    </td></tr></tbody>
</table>

<table>
  <tbody><tr>
    <td> <span class="title">Research Assistant</span>, National University of Singapore, Mar 2012 - Mar 2015  <br>
      Advisior: <a href="https://www.chuatatseng.com/" target="_blank">Prof. Tat-Seng Chua</a> (<a href="http://www.nextcenter.org/" target="_blank">NExT: NUS-Tsinghua Extreme Search Center</a>)
    </td></tr></tbody>
</table>

<h2 style="CLEAR: both;">Selected Awards</h2>


<table><tbody><tr><td>
  <span class="title">Research Achievement Award, &nbsp;&nbsp; 2022</span> &nbsp;&nbsp;
  <br> - School of Computing, National University of Singapore
</td></tr></tbody></table>

<table><tbody><tr><td>
  <span class="title"> Winner of 1st Competition on Chinese Machine Reading Comprehension (CMRC), &nbsp;&nbsp;2017</span> &nbsp;&nbsp;
  <br> - 16th China National Conference on Computational Linguistics (CCL)
</td></tr></tbody></table>

</br>

<a href='https://clustrmaps.com/site/1c1sz'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=200&t=m&d=gD2pgA_cxi0YfQEqH8dCL4qwueAnp0B1NOY6Z5eV46g'/></a>

</br>

<div>
Last update: Oct, 2024. Webpage template borrows from <a href="https://fulifeng.github.io/">Prof. Fuli Feng</a> and <a href="https://hexiangnan.github.io/">Prof. Xiangnan He</a>.</div>

</div>
</div>


</body></html>
